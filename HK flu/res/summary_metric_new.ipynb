{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48fe74a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有 74 天的 ILI+ 大于 3.860146623648647。\n",
      "ILI+ 的均值为: 3.86\n",
      "有 93 天的 ILI+ 大于 8.816373160747622。\n",
      "ILI+ 的均值为: 8.82\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def calculate_cv(series):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    return std / mean if mean != 0 else float('nan')\n",
    "\n",
    "df = pd.read_csv('flu_data_all_hk.csv')\n",
    "t = df[(df['date']>'2014-10-01') & (df['date']<'2025-06-01')]\n",
    "t1 = t[(t['date']<'2020-01-01') | (t['date']>='2023-03-01')]\n",
    "ili_mean = t1['ILI+'].mean()\n",
    "threshold = 1\n",
    "filter_df1 = t1[t1['ILI+'] > 1.5*ili_mean]\n",
    "\n",
    "\n",
    "print(f\"有 {len(filter_df1)} 天的 ILI+ 大于 {ili_mean}。\")\n",
    "print(f\"ILI+ 的均值为: {ili_mean:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../US flu/res/flu_data_all_us.csv')\n",
    "t = df[(df['date']>'2014-10-01') & (df['date']<'2025-06-01')]\n",
    "t2 = t[(t['date']<'2020-01-01') | (t['date']>='2023-03-01')]\n",
    "ili_mean = t2['ILI+'].mean()\n",
    "filter_df2 = t2[t2['ILI+'] > 1.5*ili_mean]\n",
    "\n",
    "\n",
    "print(f\"有 {len(filter_df2)} 天的 ILI+ 大于 {ili_mean}。\")\n",
    "print(f\"ILI+ 的均值为: {ili_mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff669a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019年前 ILI+ 的均值为: 5.58\n",
      "2023年后 ILI+ 的均值为: 2.51\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('flu_data_all_hk.csv')\n",
    "t1 = df[(df['date']>'1999-10-01') & (df['date']<'2019-06-01')]\n",
    "t2 = df[(df['date']>='2023-03-01')& (df['date']<'2024-12-20')]\n",
    "ili_mean1 = t1['ILI+'].mean()\n",
    "ili_mean2 = t2['ILI+'].mean()\n",
    "print(f\"2019年前 ILI+ 的均值为: {ili_mean1:.2f}\")\n",
    "print(f\"2023年后 ILI+ 的均值为: {ili_mean2:.2f}\")\n",
    "\n",
    "# 3 and 2.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce3d531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019年前 ILI+ 的均值为: 5.58\n",
      "2023年后 ILI+ 的均值为: 3.24\n",
      "2024年后 ILI+ 的均值为: 2.11\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('flu_data_all_hk.csv')\n",
    "t1 = df[(df['date']>'1999-10-01') & (df['date']<'2019-06-01')]\n",
    "t2 = df[(df['date']>='2023-08-01')& (df['date']<'2023-12-20')]\n",
    "t3 = df[(df['date']>='2023-12-20')& (df['date']<'2024-12-20')]\n",
    "\n",
    "ili_mean1 = t1['ILI+'].mean()\n",
    "ili_mean2 = t2['ILI+'].mean()\n",
    "ili_mean3 = t3['ILI+'].mean()\n",
    "print(f\"2019年前 ILI+ 的均值为: {ili_mean1:.2f}\")\n",
    "print(f\"2023年后 ILI+ 的均值为: {ili_mean2:.2f}\")\n",
    "print(f\"2024年后 ILI+ 的均值为: {ili_mean3:.2f}\")\n",
    "# 3 and 2.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35400e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HK ILI+ 阈值: 0.00\n",
      "US ILI+ 阈值: 0.00\n",
      "JP ILI+ 阈值: 0.00\n",
      "Mean: 0.005657024399031028, Std: 2.191091693235701\n",
      "Mean: 0.18336095674340747, Std: 2.7302672214384827\n",
      "Mean: -0.004598540145985405, Std: 0.6080949831804976\n",
      "HK波动得分: 0.0411\n",
      "US波动得分: 0.0288\n",
      "JP波动得分: 0.0460\n"
     ]
    }
   ],
   "source": [
    "def calculate_cv(series):\n",
    "    # series = series.abs()  # 先取绝对值\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    print(f\"Mean: {mean}, Std: {std}\")\n",
    "    return std / mean if mean != 0 else float('nan')\n",
    "\n",
    "def fluctuation_score(y, method='relative_tv'):\n",
    "    y = np.array(y)\n",
    "    dy = np.diff(y)\n",
    "    tv = np.sum(np.abs(dy))\n",
    "    return np.mean(np.abs(np.diff(y))) / np.ptp(y)\n",
    "    if method == 'relative_tv':\n",
    "        range_y = np.max(y) - np.min(y)\n",
    "        return tv / range_y if range_y > 0 else 0\n",
    "        \n",
    "    elif method == 'zscore_tv':\n",
    "        y_norm = (y - np.mean(y)) / np.std(y)\n",
    "        return np.sum(np.abs(np.diff(y_norm)))\n",
    "        \n",
    "    elif method == 'arc_length':\n",
    "        x = np.arange(len(y))\n",
    "        dx = np.diff(x)\n",
    "        segment = np.sqrt(dx**2 + dy**2)\n",
    "        straight = np.sqrt((x[-1]-x[0])**2 + (y[-1]-y[0])**2)\n",
    "        return np.sum(segment) / straight\n",
    "\n",
    "mode = 'pre'\n",
    "\n",
    "df = pd.read_csv('flu_data_all_hk.csv')\n",
    "t = df[(df['date']>'2014-10-01') & (df['date']<'2025-06-01')]\n",
    "\n",
    "if mode == 'all':\n",
    "    t1 = t[(t['date']<'2020-01-01') | (t['date']>='2023-03-01')]\n",
    "elif mode == 'pre':\n",
    "    t1 = t[(t['date']<'2020-01-01')]\n",
    "elif mode == 'post':\n",
    "    t1 = t[(t['date']>='2023-03-01')]\n",
    "\n",
    "ili_mean = t1['ILI+'].mean()\n",
    "threshold = 0\n",
    "print(f\"HK ILI+ 阈值: {threshold:.2f}\")\n",
    "filter_df1 = t1[t1['ILI+'] > threshold]\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../US flu/res/flu_data_all_us.csv')\n",
    "t = df[(df['date']>'2014-10-01') & (df['date']<'2025-06-01')]\n",
    "if mode == 'all':\n",
    "    t2 = t[(t['date']<'2020-01-01') | (t['date']>='2023-03-01')]\n",
    "elif mode == 'pre':\n",
    "    t2 = t[(t['date']<'2020-01-01')]\n",
    "elif mode == 'post':\n",
    "    t2 = t[(t['date']>='2023-03-01')]\n",
    "\n",
    "ili_mean = t2['ILI+'].mean()\n",
    "threshold = 0\n",
    "print(f\"US ILI+ 阈值: {threshold:.2f}\")\n",
    "filter_df2 = t2[t2['ILI+'] > threshold]\n",
    "\n",
    "df = pd.read_csv('../../Japan rsv/res/flu_data_all_jp.csv')\n",
    "t = df[(df['date']>'2014-10-01') & (df['date']<'2025-06-01')]\n",
    "if mode == 'all':\n",
    "    t3 = t[(t['date']<'2020-01-01') | (t['date']>='2023-03-01')]\n",
    "elif mode == 'pre':\n",
    "    t3 = t[(t['date']<'2020-01-01')]\n",
    "elif mode == 'post':\n",
    "    t3 = t[(t['date']>='2023-03-01')]\n",
    "\n",
    "ili_mean = t3['ILI+'].mean()\n",
    "threshold = 0\n",
    "print(f\"JP ILI+ 阈值: {threshold:.2f}\")\n",
    "filter_df3 = t3[t3['ILI+'] > threshold]\n",
    "\n",
    "cv_t1 = calculate_cv(filter_df1['ILI_growth_rate'])\n",
    "cv_t2 = calculate_cv(filter_df2['ILI_growth_rate'])\n",
    "cv_t3 = calculate_cv(filter_df3['ILI_growth_rate'])\n",
    "\n",
    "\n",
    "tv1 = fluctuation_score(filter_df1['ILI+'], method='relative_tv')\n",
    "tv2 = fluctuation_score(filter_df2['ILI+'], method='relative_tv')\n",
    "tv3 = fluctuation_score(filter_df3['ILI+'], method='relative_tv')\n",
    "\n",
    "print(f\"HK波动得分: {tv1:.4f}\")\n",
    "print(f\"US波动得分: {tv2:.4f}\")\n",
    "print(f\"JP波动得分: {tv3:.4f}\")\n",
    "\n",
    "#all\n",
    "# HK波动得分: 86.8750\n",
    "# US波动得分: 57.2818\n",
    "# JP波动得分: 82.6245\n",
    "\n",
    "# pre\n",
    "# HK波动得分: 60.0162\n",
    "# US波动得分: 38.6558\n",
    "# JP波动得分: 59.5839\n",
    "\n",
    "# post\n",
    "# HK波动得分: 41.5641\n",
    "# US波动得分: 15.7700\n",
    "# JP波动得分: 22.8186\n",
    "\n",
    "# pre\n",
    "# HK波动得分: 0.0411\n",
    "# US波动得分: 0.0288\n",
    "# JP波动得分: 0.0460\n",
    "\n",
    "# post\n",
    "# HK波动得分: 0.0756\n",
    "# US波动得分: 0.0316\n",
    "# JP波动得分: 0.0441\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T01:55:45.507656Z",
     "start_time": "2025-09-02T01:55:45.081978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "intervals= [\n",
    "    {'lower': 'q_1', 'upper': 'q_99', 'alpha': 0.02},    # 98% PI\n",
    "    {'lower': 'q_2', 'upper': 'q_97', 'alpha': 0.05}, # 95% PI\n",
    "    {'lower': 'q_5', 'upper': 'q_95', 'alpha': 0.1},     # 90% PI\n",
    "    {'lower': 'q_10', 'upper': 'q_90', 'alpha': 0.2},    # 80% PI\n",
    "    {'lower': 'q_15', 'upper': 'q_85', 'alpha': 0.3},    # 70% PI\n",
    "    {'lower': 'q_20', 'upper': 'q_80', 'alpha': 0.4},    # 60% PI\n",
    "    {'lower': 'q_25', 'upper': 'q_75', 'alpha': 0.5},    # 50% PI\n",
    "    {'lower': 'q_30', 'upper': 'q_70', 'alpha': 0.6},    # 40% PI\n",
    "    {'lower': 'q_35', 'upper': 'q_65', 'alpha': 0.7},    # 30% PI\n",
    "    {'lower': 'q_40', 'upper': 'q_60', 'alpha': 0.8},    # 20% PI\n",
    "    {'lower': 'q_45', 'upper': 'q_55', 'alpha': 0.9}     # 10% PI\n",
    "]\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # 避免分母为 0（如果 y_true + y_pred = 0，替换成很小的数）\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred))\n",
    "    denominator = np.where(denominator == 0, 1e-10, denominator)\n",
    "    return np.mean(np.abs(y_pred - y_true) / denominator) * 100  # 百分比形式\n",
    "\n",
    "def interval_score(y, lower, upper, alpha):\n",
    "    width = upper - lower\n",
    "    penalty_lower = (2 / alpha) * (lower - y) * (y < lower)\n",
    "    penalty_upper = (2 / alpha) * (y - upper) * (y > upper)\n",
    "    return width + penalty_lower + penalty_upper\n",
    "\n",
    "def calculate_coverate(t,rate='95'):\n",
    "    intervals = {\n",
    "              \"95\":  {'lower': 'q_2', 'upper': 'q_97'},  # 95%\n",
    "              \"80\":   {'lower': 'q_10', 'upper': 'q_90'},     # 80%\n",
    "              \"50\":   {'lower': 'q_25', 'upper': 'q_75'},     # 50%\n",
    "    }\n",
    "    interval = intervals[rate]\n",
    "\n",
    "    y = t['true']\n",
    "    metrics = {}\n",
    "    lower = t[interval['lower']] if interval['lower'] else -np.inf\n",
    "    upper = t[interval['upper']] if interval['upper'] else np.inf\n",
    "    correct = (y >= lower) & (y <= upper)\n",
    "    coverate = np.mean(correct)\n",
    "    return coverate\n",
    "\n",
    "def calculate_wis(row):\n",
    "    y = row['true']\n",
    "    median = y\n",
    "    K = len(intervals)  # 区间数量\n",
    "\n",
    "    # 计算所有区间的 IS\n",
    "    interval_scores = sum(\n",
    "        0.5 * interval['alpha'] *interval_score(y, row[interval['lower']], row[interval['upper']], interval['alpha'])\n",
    "        for interval in intervals\n",
    "    )\n",
    "\n",
    "    # 中位数误差\n",
    "    median_penalty = 0.5 * abs(y - median)\n",
    "\n",
    "    # WIS\n",
    "    wis = (interval_scores + median_penalty) / (K + 0.5)\n",
    "    return wis\n",
    "\n",
    "def median_absolute_error(y_true, y_pred):\n",
    "    absolute_errors = np.abs(y_true - y_pred)\n",
    "    return np.median(absolute_errors)\n",
    "\n",
    "def calculate_accuracy_with_tolerance(true_values, pred_values, tolerance=0.25):\n",
    "    lower_bound = true_values * (1 - tolerance)\n",
    "    upper_bound = true_values * (1 + tolerance)\n",
    "    correct = (pred_values >= lower_bound) & (pred_values <= upper_bound)\n",
    "    accuracy = np.mean(correct)\n",
    "    return accuracy\n",
    "\n",
    "def smape_score(y_true, y_pred):\n",
    "    return  np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50ae2301b96e2d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T01:56:06.374807Z",
     "start_time": "2025-09-02T01:55:45.515079Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import timedelta\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import numpy as np\n",
    "\n",
    "# # 假设您已经有这些函数定义\n",
    "# # def calculate_wis(row):\n",
    "# # def calculate_coverate(df, rate='95'):\n",
    "# # def smape_score(y_true, y_pred):\n",
    "\n",
    "# models = ['constant', 'gru', 'tcn', 'Nbeats', 'itransformer', 'ensemble_model']\n",
    "# selected_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# modes = [ 'base_stage_holi_pf','base']\n",
    "\n",
    "# # 创建第一个Excel文件（不转置版本）\n",
    "# with pd.ExcelWriter('all_models_results_original.xlsx', engine='openpyxl') as writer_original:\n",
    "\n",
    "#     # 创建第二个Excel文件（转置版本）\n",
    "#     with pd.ExcelWriter('all_models_results_transposed.xlsx', engine='openpyxl') as writer_transposed:\n",
    "\n",
    "#         for model in models:\n",
    "#             # 为每个模型创建空的DataFrame\n",
    "#             model_results = pd.DataFrame()\n",
    "\n",
    "#             for step in selected_steps:\n",
    "#                 # 为每个预测步长创建DataFrame\n",
    "#                 step_results = pd.DataFrame()\n",
    "\n",
    "#                 for mode in modes:\n",
    "#                     # 构建文件路径\n",
    "#                     path = ''\n",
    "#                     if model == 'constant':\n",
    "#                         path = 'forc_baseline.csv'\n",
    "#                     elif model == 'ensemble_model':\n",
    "#                         path = 'ensemble_model_with_intervals.csv'\n",
    "#                     elif model == 'ensemble_model_no_ol':\n",
    "#                         path = 'ensemble_model_with_intervals_no_ol.csv'\n",
    "#                     elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "#                         path = f'{model}/{model}_{mode}_42test.csv'\n",
    "#                     else:\n",
    "#                         continue\n",
    "\n",
    "#                     try:\n",
    "#                         # 读取数据并过滤\n",
    "#                         res = pd.read_csv(path)\n",
    "#                         if 'mode' in res.columns:\n",
    "#                             res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "#                         res['date'] = pd.to_datetime(res['date'])\n",
    "#                         res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "#                         invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "#                         res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "#                         res = res[(res['date_origin'] >= '2023-11-26')]\n",
    "#                         res = res.dropna()\n",
    "\n",
    "#                         # 获取当前步长的数据\n",
    "#                         t = res[res['week_ahead'] == step]\n",
    "#                         if len(t) == 0:\n",
    "#                             continue\n",
    "\n",
    "#                         # 计算指标\n",
    "#                         wis = t.apply(calculate_wis, axis=1)\n",
    "#                         wis_mean = np.mean(wis)\n",
    "#                         mae = mean_absolute_error(t['true'], t['point'])\n",
    "#                         cov_95 = calculate_coverate(t, rate='95')\n",
    "#                         smape = smape_score(t['true'], t['point'])\n",
    "\n",
    "#                         # 创建列名\n",
    "#                         step_results[f\"{mode}_WIS\"] = [wis_mean]\n",
    "#                         step_results[f\"{mode}_MAE\"] = [mae]\n",
    "#                         step_results[f\"{mode}_Coverage_95\"] = [cov_95]\n",
    "#                         step_results[f\"{mode}_SMAPE\"] = [smape]\n",
    "\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "#                         continue\n",
    "\n",
    "#                 # 将当前步长的结果添加到模型结果中\n",
    "#                 if not step_results.empty:\n",
    "#                     step_results.index = [f\"week{step}\"]\n",
    "#                     model_results = pd.concat([model_results, step_results], axis=0)\n",
    "\n",
    "#             # 保存到两个Excel文件\n",
    "#             if not model_results.empty:\n",
    "#                 # 不转置版本（原始格式）\n",
    "#                 model_results.to_excel(writer_original, sheet_name=model)\n",
    "\n",
    "#                 # 转置版本\n",
    "#                 model_results_transposed = model_results.T\n",
    "#                 model_results_transposed.to_excel(writer_transposed, sheet_name=model)\n",
    "#             else:\n",
    "#                 print(f\"No data found for model: {model}\")\n",
    "\n",
    "# print(\"所有模型结果已保存到两个文件：\")\n",
    "# print(\"1. all_models_results_original.xlsx (不转置版本)\")\n",
    "# print(\"2. all_models_results_transposed.xlsx (转置版本)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d6d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import timedelta\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import numpy as np\n",
    "\n",
    "# models = ['constant', 'gru', 'tcn', 'Nbeats', 'itransformer', 'ensemble_model']\n",
    "# selected_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# modes = ['base_stage_holi_pf', 'base']\n",
    "\n",
    "# # 创建Excel文件\n",
    "# # 创建一个字典来存储所有模型的结果，用于后续计算比值\n",
    "# all_models_data = {}\n",
    "\n",
    "# for model in models:\n",
    "#     model_results = pd.DataFrame()\n",
    "    \n",
    "#     for step in selected_steps:\n",
    "#         step_results = pd.DataFrame()\n",
    "        \n",
    "#         for mode in modes:\n",
    "#             path = ''\n",
    "#             if model == 'constant':\n",
    "#                 path = 'forc_baseline.csv'\n",
    "#             elif model == 'ensemble_model':\n",
    "#                 path = 'ensemble_model_with_intervals.csv'\n",
    "#             elif model == 'ensemble_model_no_ol':\n",
    "#                 path = 'ensemble_model_with_intervals_no_ol.csv'\n",
    "#             elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "#                 path = f'{model}/{model}_{mode}_42test.csv'\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#             try:\n",
    "#                 res = pd.read_csv(path)\n",
    "#                 if 'mode' in res.columns:\n",
    "#                     res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "#                 res['date'] = pd.to_datetime(res['date'])\n",
    "#                 res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "#                 invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "#                 res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "#                 res = res[(res['date_origin'] >= '2023-11-26')]\n",
    "#                 res = res.dropna()\n",
    "\n",
    "#                 t = res[res['week_ahead'] == step]\n",
    "#                 if len(t) == 0:\n",
    "#                     continue\n",
    "\n",
    "#                 wis = t.apply(calculate_wis, axis=1)\n",
    "#                 wis_mean = np.mean(wis)\n",
    "#                 mae = mean_absolute_error(t['true'], t['point'])\n",
    "#                 cov_95 = calculate_coverate(t, rate='95')\n",
    "#                 smape = smape_score(t['true'], t['point'])\n",
    "\n",
    "#                 step_results[f\"{mode}_WIS\"] = [wis_mean]\n",
    "#                 step_results[f\"{mode}_MAE\"] = [mae]\n",
    "#                 step_results[f\"{mode}_Coverage_95\"] = [cov_95]\n",
    "#                 step_results[f\"{mode}_SMAPE\"] = [smape]\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "#                 continue\n",
    "        \n",
    "#         if not step_results.empty:\n",
    "#             step_results.index = [f\"week{step}\"]\n",
    "#             model_results = pd.concat([model_results, step_results], axis=0)\n",
    "    \n",
    "#     if not model_results.empty:\n",
    "#         all_models_data[model] = model_results\n",
    "\n",
    "\n",
    "# all_res = []\n",
    "# # 计算比值并保存到Excel\n",
    "# for model in models:\n",
    "#     if model == 'constant':\n",
    "#         # 保存constant模型的原始结果\n",
    "#         continue\n",
    "    \n",
    "#     if model not in all_models_data:\n",
    "#         continue\n",
    "        \n",
    "#     # 创建比值DataFrame\n",
    "#     ratio_results = pd.DataFrame()\n",
    "#     step_ratio_results = pd.DataFrame()\n",
    "    \n",
    "#     # 获取constant模型的数据\n",
    "#     constant_data = all_models_data['constant']\n",
    "    \n",
    "#     # 计算每个step的比值\n",
    "#     for step in selected_steps:\n",
    "#         step_str = f\"week{step}\"\n",
    "#         if step_str not in all_models_data[model].index or step_str not in constant_data.index:\n",
    "#             continue\n",
    "            \n",
    "#         for mode in modes:\n",
    "#             for metric in ['WIS', 'MAE', 'Coverage_95', 'SMAPE']:\n",
    "#                 col_name = f\"{mode}_{metric}\"\n",
    "#                 if col_name in all_models_data[model].columns and col_name in constant_data.columns:\n",
    "#                     model_value = all_models_data[model].loc[step_str, col_name]\n",
    "#                     constant_value = constant_data.loc[step_str, col_name]\n",
    "                    \n",
    "#                     if constant_value == 0:\n",
    "#                         ratio = np.nan\n",
    "#                     else:\n",
    "#                         if metric in ['Coverage_95']:\n",
    "#                             ratio = model_value / constant_value-1\n",
    "#                         else:\n",
    "#                             ratio =1- model_value / constant_value\n",
    "                    \n",
    "#                     step_ratio_results.loc[step_str, f\"{col_name}_ratio\"] = ratio\n",
    "    \n",
    "#     # 合并step比值和总平均\n",
    "#     final_ratio_results = pd.concat([step_ratio_results, ratio_results])\n",
    "#     final_ratio_results['model']=model\n",
    "#     all_res.append(final_ratio_results)\n",
    "# ratio_df = pd.concat(all_res).reset_index().rename(columns={'index':'step'})\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19c09b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['constant', 'gru', 'gru_base','tcn','tcn_base' ,'Nbeats','Nbeats_base', 'itransformer','itransformer_base', 'ensemble_model']\n",
    "# selected_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# modes = ['base_stage_holi_pf']\n",
    "\n",
    "# # 创建字典来存储所有模型的结果\n",
    "# all_models_data = {}\n",
    "\n",
    "# for model in models:\n",
    "#     model_results = pd.DataFrame()\n",
    "#     all_data = []  # 存储所有步骤的数据\n",
    "    \n",
    "#     for step in selected_steps:\n",
    "#         for mode in modes:\n",
    "#             path = ''\n",
    "#             if model == 'constant':\n",
    "#                 path = 'forc_baseline.csv'\n",
    "#             elif model == 'ensemble_model':\n",
    "#                 path = 'ensemble_model_with_intervals.csv'\n",
    "#             elif model in ['gru_base', 'tcn_base', 'Nbeats_base', 'itransformer_base']:\n",
    "#                 model_name = model.replace('_base', '')\n",
    "#                 path = f'{model_name}/{model_name}_base_stage_42test.csv'\n",
    "#             elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "#                 path = f'{model}/{model}_{mode}_42test.csv'\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#             try:\n",
    "#                 res = pd.read_csv(path)\n",
    "#                 if 'mode' in res.columns:\n",
    "#                     res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "#                 res['date'] = pd.to_datetime(res['date'])\n",
    "#                 res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "#                 invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "#                 res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "#                 res = res[(res['date_origin'] >= '2023-11-26')]\n",
    "#                 res = res.dropna()\n",
    "\n",
    "#                 t = res[res['week_ahead'] == step]\n",
    "#                 if len(t) == 0:\n",
    "#                     continue\n",
    "\n",
    "#                 # 收集所有步骤的数据\n",
    "#                 all_data.append(t)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "#                 continue\n",
    "    \n",
    "#     if all_data:\n",
    "#         # 合并所有步骤的数据\n",
    "#         combined_data = pd.concat(all_data)\n",
    "        \n",
    "#         # 计算整体指标\n",
    "#         wis = combined_data.apply(calculate_wis, axis=1)\n",
    "#         wis_mean = np.mean(wis)\n",
    "#         mae = mean_absolute_error(combined_data['true'], combined_data['point'])\n",
    "#         cov_95 = calculate_coverate(combined_data, rate='95')\n",
    "#         smape = smape_score(combined_data['true'], combined_data['point'])\n",
    "        \n",
    "#         # 存储结果\n",
    "#         for mode in modes:\n",
    "#             model_results[f\"{mode}_WIS\"] = [wis_mean]\n",
    "#             model_results[f\"{mode}_MAE\"] = [mae]\n",
    "#             model_results[f\"{mode}_Coverage_95\"] = [cov_95]\n",
    "#             model_results[f\"{mode}_SMAPE\"] = [smape]\n",
    "        \n",
    "#         all_models_data[model] = model_results\n",
    "\n",
    "# # 计算比值\n",
    "# all_res = []\n",
    "# for model in ['gru','tcn','Nbeats','itransformer','ensemble_model']:\n",
    "#     if model == 'constant':\n",
    "#         continue  # 跳过基准模型\n",
    "    \n",
    "#     if model not in all_models_data:\n",
    "#         continue\n",
    "        \n",
    "#     ratio_results = pd.DataFrame()\n",
    "    \n",
    "#     # compare_type = model+'_base'\n",
    "#     compare_type = 'constant'\n",
    "#     # 获取constant模型的数据\n",
    "#     constant_data = all_models_data[compare_type]\n",
    "    \n",
    "#     # 计算比值\n",
    "#     for mode in modes:\n",
    "#         for metric in ['WIS', 'MAE', 'Coverage_95', 'SMAPE']:\n",
    "#             col_name = f\"{mode}_{metric}\"\n",
    "#             if col_name in all_models_data[model].columns and col_name in constant_data.columns:\n",
    "#                 model_value = all_models_data[model].loc[0, col_name]\n",
    "#                 constant_value = constant_data.loc[0, col_name]\n",
    "                \n",
    "#                 if constant_value == 0:\n",
    "#                     ratio = np.nan\n",
    "#                 else:\n",
    "#                     if metric in ['Coverage_95']:\n",
    "#                         ratio = model_value / constant_value-1\n",
    "#                     else:\n",
    "#                         ratio = 1-model_value / constant_value\n",
    "                \n",
    "#                 ratio_results[f\"{col_name}_ratio\"] = [ratio]\n",
    "    \n",
    "#     ratio_results['model'] = model\n",
    "#     all_res.append(ratio_results)\n",
    "\n",
    "# # 合并所有模型的结果\n",
    "# ratio_df_avg = pd.concat(all_res).reset_index(drop=True)\n",
    "\n",
    "# # 现在ratio_df包含所有模型相对于constant模型的比值\n",
    "# with pd.ExcelWriter(' performance_output.xlsx') as writer:\n",
    "#     # 将df1写入到名为'Sheet1'的sheet中\n",
    "#     ratio_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "    \n",
    "#     # 将df2写入到名为'Sheet2'的sheet中\n",
    "#     ratio_df_avg.to_excel(writer, sheet_name='Sheet2', index=False)\n",
    "\n",
    "# print(\"数据已成功保存到output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8ef7d28966746e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T01:56:19.693840Z",
     "start_time": "2025-09-02T01:56:06.398309Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# # 假设您已经有这些函数定义\n",
    "# # def calculate_wis(row):\n",
    "# # def calculate_coverate(df, rate='95'):\n",
    "# # def smape_score(y_true, y_pred):\n",
    "\n",
    "# models = ['constant', 'gru', 'tcn', 'Nbeats', 'itransformer', 'ensemble','ensemble_base_stage']\n",
    "# selected_steps = [0, 2, 4, 6, 8]\n",
    "# # modes = ['base_stage_holi_pf_ol', 'base_stage_holi_pf','base_stage_holi','base_stage_pf','base_stage','base']\n",
    "# modes = ['base_stage_holi_pf','base_stage']\n",
    "\n",
    "# # 创建新的Excel文件\n",
    "# with pd.ExcelWriter('all_models_results_by_mode.xlsx', engine='openpyxl') as writer:\n",
    "#     for model in models:\n",
    "#         # 为每个模型创建空的DataFrame\n",
    "#         model_results = pd.DataFrame()\n",
    "\n",
    "#         for mode in modes:\n",
    "#             # 为每个mode创建一行数据\n",
    "#             mode_data = {}\n",
    "#             if model == 'constant' and 'pf' in mode:\n",
    "#                 continue\n",
    "#             for step in selected_steps:\n",
    "#                 # 构建文件路径\n",
    "#                 path = ''\n",
    "#                 if model == 'constant':\n",
    "#                     path = 'forc_baseline.csv'\n",
    "#                 elif model == 'ensemble':\n",
    "#                     path = 'ensemble_model_with_intervals.csv'\n",
    "#                 elif model == 'ensemble_base_stage':\n",
    "#                     path = 'ensemble_model_with_intervals_base_stage.csv'\n",
    "#                 elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "#                     path = f'{model}/{model}_{mode}_42test.csv'\n",
    "#                 else:\n",
    "#                     continue\n",
    "\n",
    "#                 try:\n",
    "#                     # 读取数据并过滤\n",
    "#                     res = pd.read_csv(path)\n",
    "#                     if 'mode' in res.columns:\n",
    "#                         res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "#                     res['date'] = pd.to_datetime(res['date'])\n",
    "#                     res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "#                     invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "#                     res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "#                     res = res[(res['date_origin'] >= '2023-11-26')]\n",
    "#                     # res = res[(res['date_origin'] < '2024-11-26')]\n",
    "#                     # res = res[(res['date_origin'] > '2024-11-26')]\n",
    "#                     res = res.dropna()\n",
    "\n",
    "#                     # 获取当前步长的数据\n",
    "#                     t = res[res['week_ahead'] == step]\n",
    "#                     if len(t) == 0:\n",
    "#                         continue\n",
    "\n",
    "#                     # 计算指标\n",
    "#                     wis = t.apply(calculate_wis, axis=1)\n",
    "#                     wis_mean = np.mean(wis)\n",
    "#                     mae = mean_absolute_error(t['true'], t['point'])\n",
    "#                     cov_95 = calculate_coverate(t, rate='95')\n",
    "#                     smape = smape_score(t['true'], t['point'])\n",
    "\n",
    "#                     # 添加指标到mode_data字典\n",
    "#                     mode_data[f\"week{step}_WIS\"] = round(wis_mean, 2)\n",
    "#                     mode_data[f\"week{step}_MAE\"] = round(mae, 2)\n",
    "#                     # mode_data[f\"week{step}_Coverage_95\"] = cov_95\n",
    "#                     mode_data[f\"week{step}_SMAPE\"] = round(smape, 2)\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "#                     continue\n",
    "\n",
    "#             # 将当前mode的结果添加到模型结果中\n",
    "#             mode_name = 'Base'\n",
    "#             if 'pf' in mode:\n",
    "#                 mode_name = 'SIRSPF-H'\n",
    "#             index_name = model+' '+mode_name\n",
    "#             if mode_data:\n",
    "#                 mode_df = pd.DataFrame(mode_data, index=[index_name])\n",
    "#                 model_results = pd.concat([model_results, mode_df], axis=0)\n",
    "\n",
    "#         # 保存到Excel文件\n",
    "#         if not model_results.empty:\n",
    "#             model_results.to_excel(writer, sheet_name=model)\n",
    "#         else:\n",
    "#             print(f\"No data found for model: {model}\")\n",
    "\n",
    "# print(\"所有模型结果已保存到文件：all_models_results_by_mode.xlsx\")\n",
    "# print(\"格式说明：每个模型一个sheet，每行代表一个mode，列按照week顺序排列，每个week包含所有指标\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['constant', 'gru', 'tcn', 'Nbeats', 'itransformer', 'ensemble','ensemble_base_stage']\n",
    "selected_steps = [0, 2, 4, 6, 8]\n",
    "modes = ['base_stage_holi_pf','base_stage']\n",
    "\n",
    "# 创建新的Excel文件\n",
    "with pd.ExcelWriter('all_models_results_by_mode.xlsx', engine='openpyxl') as writer:\n",
    "    # 创建一个空的DataFrame用于存储所有模型的结果\n",
    "    all_models_results = pd.DataFrame()\n",
    "\n",
    "    for model in models:\n",
    "        for mode in modes:\n",
    "            # 为每个mode创建一行数据\n",
    "            mode_data = {}\n",
    "            if model == 'constant' and 'pf' in mode:\n",
    "                continue\n",
    "            for step in selected_steps:\n",
    "                # 构建文件路径\n",
    "                path = ''\n",
    "                if model == 'constant':\n",
    "                    path = 'forc_baseline.csv'\n",
    "                elif model == 'ensemble':\n",
    "                    path = 'ensemble_model_with_intervals.csv'\n",
    "                elif model == 'ensemble_base_stage':\n",
    "                    path = 'ensemble_model_with_intervals_base_stage.csv'\n",
    "                elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "                    path = f'{model}/{model}_{mode}_42test.csv'\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # 读取数据并过滤\n",
    "                    res = pd.read_csv(path)\n",
    "                    if 'mode' in res.columns:\n",
    "                        res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "                    res['date'] = pd.to_datetime(res['date'])\n",
    "                    res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "                    invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "                    res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "                    res = res[(res['date_origin'] >= '2023-11-26')]\n",
    "                    res = res.dropna()\n",
    "\n",
    "                    # 获取当前步长的数据\n",
    "                    t = res[res['week_ahead'] == step]\n",
    "                    if len(t) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # 计算指标\n",
    "                    wis = t.apply(calculate_wis, axis=1)\n",
    "                    wis_mean = np.mean(wis)\n",
    "                    mae = mean_absolute_error(t['true'], t['point'])\n",
    "                    cov_95 = calculate_coverate(t, rate='95')\n",
    "                    smape = smape_score(t['true'], t['point'])\n",
    "\n",
    "                    # 添加指标到mode_data字典\n",
    "                    mode_data[f\"week{step}_WIS\"] = round(wis_mean, 3)\n",
    "                    mode_data[f\"week{step}_MAE\"] = round(mae, 3)\n",
    "                    # mode_data[f\"week{step}_Coverage_95\"] = cov_95\n",
    "                    mode_data[f\"week{step}_SMAPE\"] = round(smape, 3)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # 将当前mode的结果添加到总表中\n",
    "            mode_name = 'Base'\n",
    "            if 'pf' in mode:\n",
    "                mode_name = 'SIRSPF-H'\n",
    "            index_name = model + ' ' + mode_name\n",
    "            if mode_data:\n",
    "                mode_df = pd.DataFrame(mode_data, index=[index_name])\n",
    "                all_models_results = pd.concat([all_models_results, mode_df], axis=0)\n",
    "\n",
    "    # 保存合并后的总表\n",
    "    if not all_models_results.empty:\n",
    "        all_models_results.to_excel(writer, sheet_name=\"All_Models_Summary\")\n",
    "    else:\n",
    "        print(\"No data found for any model\")\n",
    "\n",
    "print(\"所有模型结果已保存到文件：all_models_results_by_mode.xlsx\")\n",
    "print(\"合并后的总表保存在 'All_Models_Summary' sheet 中\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
