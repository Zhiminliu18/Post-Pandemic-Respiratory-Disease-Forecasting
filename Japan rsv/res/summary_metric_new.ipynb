{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T01:55:45.507656Z",
     "start_time": "2025-09-02T01:55:45.081978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "intervals= [\n",
    "    {'lower': 'q_1', 'upper': 'q_99', 'alpha': 0.02},    # 98% PI\n",
    "    {'lower': 'q_2', 'upper': 'q_97', 'alpha': 0.05}, # 95% PI\n",
    "    {'lower': 'q_5', 'upper': 'q_95', 'alpha': 0.1},     # 90% PI\n",
    "    {'lower': 'q_10', 'upper': 'q_90', 'alpha': 0.2},    # 80% PI\n",
    "    {'lower': 'q_15', 'upper': 'q_85', 'alpha': 0.3},    # 70% PI\n",
    "    {'lower': 'q_20', 'upper': 'q_80', 'alpha': 0.4},    # 60% PI\n",
    "    {'lower': 'q_25', 'upper': 'q_75', 'alpha': 0.5},    # 50% PI\n",
    "    {'lower': 'q_30', 'upper': 'q_70', 'alpha': 0.6},    # 40% PI\n",
    "    {'lower': 'q_35', 'upper': 'q_65', 'alpha': 0.7},    # 30% PI\n",
    "    {'lower': 'q_40', 'upper': 'q_60', 'alpha': 0.8},    # 20% PI\n",
    "    {'lower': 'q_45', 'upper': 'q_55', 'alpha': 0.9}     # 10% PI\n",
    "]\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # 避免分母为 0（如果 y_true + y_pred = 0，替换成很小的数）\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred))\n",
    "    denominator = np.where(denominator == 0, 1e-10, denominator)\n",
    "    return np.mean(np.abs(y_pred - y_true) / denominator) * 100  # 百分比形式\n",
    "\n",
    "def interval_score(y, lower, upper, alpha):\n",
    "    width = upper - lower\n",
    "    penalty_lower = (2 / alpha) * (lower - y) * (y < lower)\n",
    "    penalty_upper = (2 / alpha) * (y - upper) * (y > upper)\n",
    "    return width + penalty_lower + penalty_upper\n",
    "\n",
    "def calculate_coverate(t,rate='95'):\n",
    "    intervals = {\n",
    "              \"95\":  {'lower': 'q_2', 'upper': 'q_97'},  # 95%\n",
    "              \"80\":   {'lower': 'q_10', 'upper': 'q_90'},     # 80%\n",
    "              \"50\":   {'lower': 'q_25', 'upper': 'q_75'},     # 50%\n",
    "    }\n",
    "    interval = intervals[rate]\n",
    "\n",
    "    y = t['true']\n",
    "    metrics = {}\n",
    "    lower = t[interval['lower']] if interval['lower'] else -np.inf\n",
    "    upper = t[interval['upper']] if interval['upper'] else np.inf\n",
    "    correct = (y >= lower) & (y <= upper)\n",
    "    coverate = np.mean(correct)\n",
    "    return coverate\n",
    "\n",
    "def calculate_wis(row):\n",
    "    y = row['true']\n",
    "    median = y\n",
    "    K = len(intervals)  # 区间数量\n",
    "\n",
    "    # 计算所有区间的 IS\n",
    "    interval_scores = sum(\n",
    "        0.5 * interval['alpha'] *interval_score(y, row[interval['lower']], row[interval['upper']], interval['alpha'])\n",
    "        for interval in intervals\n",
    "    )\n",
    "\n",
    "    # 中位数误差\n",
    "    median_penalty = 0.5 * abs(y - median)\n",
    "\n",
    "    # WIS\n",
    "    wis = (interval_scores + median_penalty) / (K + 0.5)\n",
    "    return wis\n",
    "\n",
    "def median_absolute_error(y_true, y_pred):\n",
    "    absolute_errors = np.abs(y_true - y_pred)\n",
    "    return np.median(absolute_errors)\n",
    "\n",
    "def calculate_accuracy_with_tolerance(true_values, pred_values, tolerance=0.25):\n",
    "    lower_bound = true_values * (1 - tolerance)\n",
    "    upper_bound = true_values * (1 + tolerance)\n",
    "    correct = (pred_values >= lower_bound) & (pred_values <= upper_bound)\n",
    "    accuracy = np.mean(correct)\n",
    "    return accuracy\n",
    "\n",
    "def smape_score(y_true, y_pred):\n",
    "    return  np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ae2301b96e2d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T01:56:06.374807Z",
     "start_time": "2025-09-02T01:55:45.515079Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import timedelta\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import numpy as np\n",
    "\n",
    "# # 假设您已经有这些函数定义\n",
    "# # def calculate_wis(row):\n",
    "# # def calculate_coverate(df, rate='95'):\n",
    "# # def smape_score(y_true, y_pred):\n",
    "\n",
    "# models = ['constant', 'gru', 'tcn', 'Nbeats', 'itransformer', 'ensemble_model']\n",
    "# selected_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# modes = [ 'base_stage_holi_pf','base']\n",
    "\n",
    "# # 创建第一个Excel文件（不转置版本）\n",
    "# with pd.ExcelWriter('all_models_results_original.xlsx', engine='openpyxl') as writer_original:\n",
    "\n",
    "#     # 创建第二个Excel文件（转置版本）\n",
    "#     with pd.ExcelWriter('all_models_results_transposed.xlsx', engine='openpyxl') as writer_transposed:\n",
    "\n",
    "#         for model in models:\n",
    "#             # 为每个模型创建空的DataFrame\n",
    "#             model_results = pd.DataFrame()\n",
    "\n",
    "#             for step in selected_steps:\n",
    "#                 # 为每个预测步长创建DataFrame\n",
    "#                 step_results = pd.DataFrame()\n",
    "\n",
    "#                 for mode in modes:\n",
    "#                     # 构建文件路径\n",
    "#                     path = ''\n",
    "#                     if model == 'constant':\n",
    "#                         path = 'forc_baseline.csv'\n",
    "#                     elif model == 'ensemble_model':\n",
    "#                         path = 'ensemble_model_with_intervals.csv'\n",
    "#                     elif model == 'ensemble_model_no_ol':\n",
    "#                         path = 'ensemble_model_with_intervals_no_ol.csv'\n",
    "#                     elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "#                         path = f'{model}/{model}_{mode}_42test.csv'\n",
    "#                     else:\n",
    "#                         continue\n",
    "\n",
    "#                     try:\n",
    "#                         # 读取数据并过滤\n",
    "#                         res = pd.read_csv(path)\n",
    "#                         if 'mode' in res.columns:\n",
    "#                             res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "#                         res['date'] = pd.to_datetime(res['date'])\n",
    "#                         res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "#                         invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "#                         res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "#                         res = res[(res['date_origin'] >= '2023-11-26')]\n",
    "#                         res = res.dropna()\n",
    "\n",
    "#                         # 获取当前步长的数据\n",
    "#                         t = res[res['week_ahead'] == step]\n",
    "#                         if len(t) == 0:\n",
    "#                             continue\n",
    "\n",
    "#                         # 计算指标\n",
    "#                         wis = t.apply(calculate_wis, axis=1)\n",
    "#                         wis_mean = np.mean(wis)\n",
    "#                         mae = mean_absolute_error(t['true'], t['point'])\n",
    "#                         cov_95 = calculate_coverate(t, rate='95')\n",
    "#                         smape = smape_score(t['true'], t['point'])\n",
    "\n",
    "#                         # 创建列名\n",
    "#                         step_results[f\"{mode}_WIS\"] = [wis_mean]\n",
    "#                         step_results[f\"{mode}_MAE\"] = [mae]\n",
    "#                         step_results[f\"{mode}_Coverage_95\"] = [cov_95]\n",
    "#                         step_results[f\"{mode}_SMAPE\"] = [smape]\n",
    "\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "#                         continue\n",
    "\n",
    "#                 # 将当前步长的结果添加到模型结果中\n",
    "#                 if not step_results.empty:\n",
    "#                     step_results.index = [f\"week{step}\"]\n",
    "#                     model_results = pd.concat([model_results, step_results], axis=0)\n",
    "\n",
    "#             # 保存到两个Excel文件\n",
    "#             if not model_results.empty:\n",
    "#                 # 不转置版本（原始格式）\n",
    "#                 model_results.to_excel(writer_original, sheet_name=model)\n",
    "\n",
    "#                 # 转置版本\n",
    "#                 model_results_transposed = model_results.T\n",
    "#                 model_results_transposed.to_excel(writer_transposed, sheet_name=model)\n",
    "#             else:\n",
    "#                 print(f\"No data found for model: {model}\")\n",
    "\n",
    "# print(\"所有模型结果已保存到两个文件：\")\n",
    "# print(\"1. all_models_results_original.xlsx (不转置版本)\")\n",
    "# print(\"2. all_models_results_transposed.xlsx (转置版本)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d6d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import timedelta\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import numpy as np\n",
    "\n",
    "# models = ['constant', 'gru', 'tcn', 'Nbeats', 'itransformer', 'ensemble_model']\n",
    "# selected_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# modes = ['base_week_holi_pf', 'base_week']\n",
    "\n",
    "# # 创建Excel文件\n",
    "# # 创建一个字典来存储所有模型的结果，用于后续计算比值\n",
    "# all_models_data = {}\n",
    "\n",
    "# for model in models:\n",
    "#     model_results = pd.DataFrame()\n",
    "    \n",
    "#     for step in selected_steps:\n",
    "#         step_results = pd.DataFrame()\n",
    "        \n",
    "#         for mode in modes:\n",
    "#             path = ''\n",
    "#             if model == 'constant':\n",
    "#                 path = 'forc_baseline.csv'\n",
    "#             elif model == 'ensemble_model':\n",
    "#                 path = 'ensemble_model_with_intervals.csv'\n",
    "#             elif model == 'ensemble_model_no_ol':\n",
    "#                 path = 'ensemble_model_with_intervals_no_ol.csv'\n",
    "#             elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "#                 path = f'{model}/{model}_{mode}_42test.csv'\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#             try:\n",
    "#                 res = pd.read_csv(path)\n",
    "#                 if 'mode' in res.columns:\n",
    "#                     res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "#                 res['date'] = pd.to_datetime(res['date'])\n",
    "#                 res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "#                 invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "#                 # res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "#                 res = res[(res['date_origin'] >= '2024-02-11')]\n",
    "#                 res = res.dropna()\n",
    "\n",
    "#                 t = res[res['week_ahead'] == step]\n",
    "#                 if len(t) == 0:\n",
    "#                     continue\n",
    "\n",
    "#                 wis = t.apply(calculate_wis, axis=1)\n",
    "#                 wis_mean = np.mean(wis)\n",
    "#                 mae = mean_absolute_error(t['true'], t['point'])\n",
    "#                 cov_95 = calculate_coverate(t, rate='95')\n",
    "#                 smape = smape_score(t['true'], t['point'])\n",
    "\n",
    "#                 step_results[f\"{mode}_WIS\"] = [wis_mean]\n",
    "#                 step_results[f\"{mode}_MAE\"] = [mae]\n",
    "#                 step_results[f\"{mode}_Coverage_95\"] = [cov_95]\n",
    "#                 step_results[f\"{mode}_SMAPE\"] = [smape]\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "#                 continue\n",
    "        \n",
    "#         if not step_results.empty:\n",
    "#             step_results.index = [f\"week{step}\"]\n",
    "#             model_results = pd.concat([model_results, step_results], axis=0)\n",
    "    \n",
    "#     if not model_results.empty:\n",
    "#         all_models_data[model] = model_results\n",
    "\n",
    "\n",
    "# all_res = []\n",
    "# # 计算比值并保存到Excel\n",
    "# for model in models:\n",
    "#     if model == 'constant':\n",
    "#         # 保存constant模型的原始结果\n",
    "#         continue\n",
    "    \n",
    "#     if model not in all_models_data:\n",
    "#         continue\n",
    "        \n",
    "#     # 创建比值DataFrame\n",
    "#     ratio_results = pd.DataFrame()\n",
    "#     step_ratio_results = pd.DataFrame()\n",
    "    \n",
    "#     # 获取constant模型的数据\n",
    "#     constant_data = all_models_data['constant']\n",
    "    \n",
    "#     # 计算每个step的比值\n",
    "#     for step in selected_steps:\n",
    "#         step_str = f\"week{step}\"\n",
    "#         if step_str not in all_models_data[model].index or step_str not in constant_data.index:\n",
    "#             continue\n",
    "            \n",
    "#         for mode in modes:\n",
    "#             for metric in ['WIS', 'MAE', 'Coverage_95', 'SMAPE']:\n",
    "#                 col_name = f\"{mode}_{metric}\"\n",
    "#                 if col_name in all_models_data[model].columns and col_name in constant_data.columns:\n",
    "#                     model_value = all_models_data[model].loc[step_str, col_name]\n",
    "#                     constant_value = constant_data.loc[step_str, col_name]\n",
    "                    \n",
    "#                     if constant_value == 0:\n",
    "#                         ratio = np.nan\n",
    "#                     else:\n",
    "#                         if metric in ['Coverage_95']:\n",
    "#                             ratio = model_value / constant_value-1\n",
    "#                         else:\n",
    "#                             ratio =1- model_value / constant_value\n",
    "                    \n",
    "#                     step_ratio_results.loc[step_str, f\"{col_name}_ratio\"] = ratio\n",
    "    \n",
    "#     # 合并step比值和总平均\n",
    "#     final_ratio_results = pd.concat([step_ratio_results, ratio_results])\n",
    "#     final_ratio_results['model']=model\n",
    "#     all_res.append(final_ratio_results)\n",
    "# ratio_df = pd.concat(all_res).reset_index().rename(columns={'index':'step'})\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19c09b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# models = ['constant', 'gru','gru_week', 'tcn','tcn_week', 'Nbeats','Nbeats_week', 'itransformer','itransformer_week', 'ensemble_model']\n",
    "# selected_steps = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "# modes = ['base_week_holi_pf']\n",
    "\n",
    "# # 创建字典来存储所有模型的结果\n",
    "# all_models_data = {}\n",
    "\n",
    "# for model in models:\n",
    "#     model_results = pd.DataFrame()\n",
    "#     all_data = []  # 存储所有步骤的数据\n",
    "    \n",
    "#     for step in selected_steps:\n",
    "#         for mode in modes:\n",
    "#             path = ''\n",
    "#             if model == 'constant':\n",
    "#                 path = 'forc_baseline.csv'\n",
    "#             elif model == 'ensemble_model':\n",
    "#                 path = 'ensemble_model_with_intervals.csv'\n",
    "#             elif model == 'ensemble_model_no_ol':\n",
    "#                 path = 'ensemble_model_with_intervals_no_ol.csv'\n",
    "#             elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "#                 path = f'{model}/{model}_{mode}_42test.csv'\n",
    "#             elif model in ['gru_week', 'tcn_week', 'Nbeats_week', 'itransformer_week']:\n",
    "#                 model_name = model.replace('_week', '')\n",
    "#                 path = f'{model_name}/{model_name}_base_week_42test.csv'\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#             try:\n",
    "#                 res = pd.read_csv(path)\n",
    "#                 if 'mode' in res.columns:\n",
    "#                     res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "#                 res['date'] = pd.to_datetime(res['date'])\n",
    "#                 res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "#                 invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "#                 # res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "#                 res = res[(res['date_origin'] >= '2024-02-11')]\n",
    "#                 res = res.dropna()\n",
    "\n",
    "#                 t = res[res['week_ahead'] == step]\n",
    "#                 if len(t) == 0:\n",
    "#                     continue\n",
    "\n",
    "#                 # 收集所有步骤的数据\n",
    "#                 all_data.append(t)\n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "#                 continue\n",
    "    \n",
    "#     if all_data:\n",
    "#         # 合并所有步骤的数据\n",
    "#         combined_data = pd.concat(all_data)\n",
    "        \n",
    "#         # 计算整体指标\n",
    "#         wis = combined_data.apply(calculate_wis, axis=1)\n",
    "#         wis_mean = np.mean(wis)\n",
    "#         mae = mean_absolute_error(combined_data['true'], combined_data['point'])\n",
    "#         cov_95 = calculate_coverate(combined_data, rate='95')\n",
    "#         smape = smape_score(combined_data['true'], combined_data['point'])\n",
    "        \n",
    "#         # 存储结果\n",
    "#         for mode in modes:\n",
    "#             model_results[f\"{mode}_WIS\"] = [wis_mean]\n",
    "#             model_results[f\"{mode}_MAE\"] = [mae]\n",
    "#             model_results[f\"{mode}_Coverage_95\"] = [cov_95]\n",
    "#             model_results[f\"{mode}_SMAPE\"] = [smape]\n",
    "        \n",
    "#         all_models_data[model] = model_results\n",
    "\n",
    "# # 计算比值\n",
    "# all_res = []\n",
    "# for model in ['gru','tcn','Nbeats','itransformer','ensemble_model']:\n",
    "#     if model == 'constant':\n",
    "#         continue  # 跳过基准模型\n",
    "    \n",
    "#     if model not in all_models_data:\n",
    "#         continue\n",
    "        \n",
    "#     ratio_results = pd.DataFrame()\n",
    "#     # compare_type = model+'_week'\n",
    "#     compare_type = 'constant'\n",
    "#     # 获取constant模型的数据\n",
    "#     constant_data = all_models_data[compare_type]\n",
    "    \n",
    "#     # 计算比值\n",
    "#     for mode in modes:\n",
    "#         for metric in ['WIS', 'MAE', 'Coverage_95', 'SMAPE']:\n",
    "#             col_name = f\"{mode}_{metric}\"\n",
    "#             if col_name in all_models_data[model].columns and col_name in constant_data.columns:\n",
    "#                 model_value = all_models_data[model].loc[0, col_name]\n",
    "#                 constant_value = constant_data.loc[0, col_name]\n",
    "                \n",
    "#                 if constant_value == 0:\n",
    "#                     ratio = np.nan\n",
    "#                 else:\n",
    "#                     if metric in ['Coverage_95']:\n",
    "#                         ratio = model_value / constant_value-1\n",
    "#                     else:\n",
    "#                         ratio =1- model_value / constant_value\n",
    "                \n",
    "#                 ratio_results[f\"{col_name}_ratio\"] = [ratio]\n",
    "    \n",
    "#     ratio_results['model'] = model\n",
    "#     all_res.append(ratio_results)\n",
    "\n",
    "# # 合并所有模型的结果\n",
    "# ratio_df_avg = pd.concat(all_res).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13005a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(' performance_output.xlsx') as writer:\n",
    "#     # 将df1写入到名为'Sheet1'的sheet中\n",
    "#     ratio_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "    \n",
    "#     # 将df2写入到名为'Sheet2'的sheet中\n",
    "#     ratio_df_avg.to_excel(writer, sheet_name='Sheet2', index=False)\n",
    "\n",
    "# print(\"数据已成功保存到output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef7d28966746e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T01:56:19.693840Z",
     "start_time": "2025-09-02T01:56:06.398309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有模型结果已保存到文件：all_models_results_by_mode.xlsx\n",
      "格式说明：每个模型一个sheet，每行代表一个mode，列按照week顺序排列，每个week包含所有指标\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# 假设您已经有这些函数定义\n",
    "# def calculate_wis(row):\n",
    "# def calculate_coverate(df, rate='95'):\n",
    "# def smape_score(y_true, y_pred):\n",
    "\n",
    "models = ['constant', 'gru', 'tcn', 'Nbeats', 'itransformer', 'ensemble_model','ensemble_model_base']\n",
    "selected_steps = [0,2, 4, 6, 8]\n",
    "# modes = ['base_stage_holi_pf_ol', 'base_stage_holi_pf','base_stage_holi','base_stage_pf','base_stage','base']\n",
    "modes = ['base_week_holi_pf','base_week']\n",
    "\n",
    "# 创建新的Excel文件\n",
    "with pd.ExcelWriter('all_models_results_by_mode.xlsx', engine='openpyxl') as writer:\n",
    "    all_models_results = pd.DataFrame()\n",
    "\n",
    "    for model in models:\n",
    "        # 为每个模型创建空的DataFrame\n",
    "\n",
    "        for mode in modes:\n",
    "            if model == 'constant' and 'pf' in mode:\n",
    "                continue\n",
    "            # 为每个mode创建一行数据\n",
    "            mode_data = {}\n",
    "\n",
    "            for step in selected_steps:\n",
    "                # 构建文件路径\n",
    "                path = ''\n",
    "                if model == 'constant':\n",
    "                    path = 'forc_baseline.csv'\n",
    "                elif model == 'ensemble_model':\n",
    "                    path = 'ensemble_model_with_intervals.csv'\n",
    "                elif model == 'ensemble_model_base':\n",
    "                    path = 'ensemble_model_with_intervals_base_week.csv'\n",
    "                elif model in ['gru', 'tcn', 'Nbeats', 'itransformer']:\n",
    "                    path = f'{model}/{model}_{mode}_42test.csv'\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # 读取数据并过滤\n",
    "                    res = pd.read_csv(path)\n",
    "                    if 'mode' in res.columns:\n",
    "                        res = res[(res['mode'] == 'train')|(res['mode'] == 'train_seed42')]\n",
    "                    res['date'] = pd.to_datetime(res['date'])\n",
    "                    res['date_origin'] = res['date'] - res['week_ahead'] * timedelta(days=7)\n",
    "\n",
    "                    invalid_dates = res.groupby('date').filter(lambda x: (x['true'] <= 1).any())['date'].unique()\n",
    "                    # res = res[~res['date_origin'].isin(invalid_dates)]\n",
    "                    res = res[(res['date_origin'] >= '2024-02-11')]\n",
    "                    # res = res[(res['date_origin'] < '2024-11-26')]\n",
    "                    # res = res[(res['date_origin'] > '2024-11-26')]\n",
    "                    res = res.dropna()\n",
    "\n",
    "                    # 获取当前步长的数据\n",
    "                    t = res[res['week_ahead'] == step]\n",
    "                    if len(t) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # 计算指标\n",
    "                    wis = t.apply(calculate_wis, axis=1)\n",
    "                    wis_mean = np.mean(wis)\n",
    "                    mae = mean_absolute_error(t['true'], t['point'])\n",
    "                    cov_95 = calculate_coverate(t, rate='95')\n",
    "                    smape = smape_score(t['true'], t['point'])\n",
    "\n",
    "                    # 添加指标到mode_data字典\n",
    "                    mode_data[f\"week{step}_WIS\"] = round(wis_mean,3)\n",
    "                    mode_data[f\"week{step}_MAE\"] = round(mae,3)\n",
    "                    # mode_data[f\"week{step}_Coverage_95\"] = cov_95\n",
    "                    mode_data[f\"week{step}_SMAPE\"] = round(smape,3zz)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {model} with mode {mode} at step {step}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # 将当前mode的结果添加到模型结果中\n",
    "            # 将当前mode的结果添加到总表中\n",
    "            mode_name = 'Base'\n",
    "            if 'pf' in mode:\n",
    "                mode_name = 'SIRSPF-H'\n",
    "            index_name = model + ' ' + mode_name\n",
    "            if mode_data:\n",
    "                mode_df = pd.DataFrame(mode_data, index=[index_name])\n",
    "                all_models_results = pd.concat([all_models_results, mode_df], axis=0)\n",
    "    # 保存合并后的总表\n",
    "    if not all_models_results.empty:\n",
    "        all_models_results.to_excel(writer, sheet_name=\"All_Models_Summary\")\n",
    "    else:\n",
    "        print(\"No data found for any model\")\n",
    "\n",
    "print(\"所有模型结果已保存到文件：all_models_results_by_mode.xlsx\")\n",
    "print(\"格式说明：每个模型一个sheet，每行代表一个mode，列按照week顺序排列，每个week包含所有指标\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
